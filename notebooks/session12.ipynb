{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load and preprocess MNIST data__\n",
    "\n",
    "See Session 7 notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initialise Gridsearch parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the default model, here given the name 'classifier'\n",
    "pipe = Pipeline([('classifier' , LogisticRegression())])\n",
    "\n",
    "\n",
    "# Set tunable parameters for grid search\n",
    "penalties = ['l1', 'l2'] # different regularization parameters\n",
    "C = [1.0, 0.1, 0.01]     # different regularization 'strengths'\n",
    "solvers = ['liblinear']  # different solvers - check all of the sklearn docs\n",
    "\n",
    "# Create parameter grid (a Python dictionary)\n",
    "parameters = dict(classifier__penalty = penalties,  # notice how we use the name 'classifier'\n",
    "                  classifier__C = C,\n",
    "                  classifier__solver = solvers)\n",
    "\n",
    "# Choose which metrics on which we want to optimise\n",
    "scores = ['precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Iterate over scoring types__\n",
    "\n",
    "For example, we first optimise for the parameters which result in the best weighted precision score; next we optimse for weighted recall; and lastly for weighted-F1. \n",
    "\n",
    "This allows us to inspet the model in a more nuanced way, seeing how different parameters affect performance across different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in scores:\n",
    "    print(f\"# Tuning hyper-parameters for {score}\")\n",
    "    print()\n",
    "    \n",
    "    # Initialise Gridsearch with predefined parameters\n",
    "    clf = GridSearchCV(pipe, \n",
    "                       parameters, \n",
    "                       scoring= f\"{score}_weighted\",\n",
    "                       cv=10) # use 10-fold cross-validation\n",
    "    # Fit\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    print(\"Best parameters set found on training data:\")\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on training data:\")\n",
    "    print()\n",
    "    # get all means\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    # get all standard deviations\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    # get parameter combinations\n",
    "    params = clf.cv_results_['params']\n",
    "\n",
    "    # print means, standard deviations , and parameters for all runs\n",
    "    i = 0\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        # 2*standard deviation covers 95% of the spread - check out the 68–95–99.7 rule\n",
    "        print(f\"Run {i}: {round(mean,3)} (SD=±{round(stdev*2, 3)}), using {param}\")\n",
    "        i += 1\n",
    "    print()\n",
    "    \n",
    "    # Print details classification report\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full training set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex DL models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load tools from ```tf.keras()```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Inspect image shapes for input layer size__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define model__\n",
    "\n",
    "We begin by defining our model, just as we normally would. The only difference is that we wrap the whole thign in a function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(optimizer='adam'):\n",
    "    # create a sequential model\n",
    "    model = Sequential()\n",
    "    # add input layer of 64 nodes and hidden layer of 32, ReLU activation\n",
    "    model.add(Dense(32, input_shape=(64,), activation=\"relu\"))\n",
    "    # hidden layer of 16 nodes, ReLU activation\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    # classificaiton layer, 10 classes with softmaxa ctivation\n",
    "    model.add(Dense(10, activation=\"softmax\")) \n",
    "    # categorical cross-entropy, optimizer defined in function call\n",
    "    model.compile(loss=\"categorical_crossentropy\", \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    # return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create model for ```sklearn```__\n",
    "\n",
    "We take the predefined neural network model above and run it through ```KerasClassifier```. This returns an object that can be used in the ```sklearn``` pipeline, just like a ```LogisticRegression()``` classifier, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=nn_model, # build the model defined in nn_model\n",
    "                        verbose=0)         # set to 1 for verbose output during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define grid search parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['sgd', 'adam']\n",
    "# range of epochs to run\n",
    "epochs = [5, 10]\n",
    "# variable batch sizes\n",
    "batches = [5, 10]\n",
    "\n",
    "# create search grid\n",
    "param_grid = dict(optimizer=optimizers, \n",
    "                  epochs=epochs, \n",
    "                  batch_size=batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initialise Gridsearch with model and parameter grid__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    n_jobs=-1,\n",
    "                    cv=5,\n",
    "                    scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fit to the data and labels__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Print best results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best results, rounding values to 3 decimal places\n",
    "print(f\"Best run: {round(grid_result.best_score_,3)} using {grid_result.best_params_}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Show all runs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all means\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "# get all standard deviations\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "# get parameter combinations\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "# print means, standard deviations, and parameters for all runs\n",
    "i = 0\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Run {i}: {round(mean,3)} (SD=±{round(2*stdev, 3)}), using {param}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv101",
   "language": "python",
   "name": "cv101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
